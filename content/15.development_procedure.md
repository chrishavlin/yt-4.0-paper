## Development Procedure {#sec:development}

`yt` is developed openly.
During the Spring of 2017, development transitioned from occurring on [Bitbucket](https://bitbucket.org/yt_analysis/) to [GitHub](https://github.com/yt-project/), and the source code management system was changed from [Mercurial](https://www.mercurial-scm.org/) to [git](https://git-scm.org/).
Development occurs through the "pull request" model, wherein changes to the codebase are made and then requested to be included in the primary repository.
Typically, there are two branches of development, and occasionally three.  The first of these is the "stable" branch, which is much slower-paced, and typically only modified during the release periods.
The second is that of "main" (formerly "master", which is the conventional term in git terminology, and renamed in early 2021; the corresponding mercurial term would be "default") which is where current development takes place.
The "main" branch is meant to be for development proceeding that does not drastically disrupt usage patterns.
Occasionally, such as during the development of `yt` 4.0, a third branch is included in the primary repository.
This development branch is open for large and potentially disruptive changes, but in order to centralize code review and developer attention it takes place there.
For instance, during the development of `yt` 4.0, the branch `yt-4.0` was where the global mesh was removed and where the units subsystem was removed and replaced with `unyt`.

This three-pronged approach generally has suited the community; the process of backporting changes from the "main" branch to the "stable" branch can be time-consuming.
However, balancing the needs of a community requiring stable methods for analyzing data against the ease of development suggests that this is a toll worth paying.

In general, the development of `yt` is reasonably top-heavy, with the majority of contributions coming from a core group of individuals.
We discuss the implications of this on sustainability in Section @sec:sustainability, and provide here a graph of the contributions over time.
Of particular note is that the development history of yt is also highly bifurcated between version control systems and developer practice.
In the past, yt developers tended to commit frequently and include all of the individual development history of individual features or bug fixes.
Recent practice, however, is more inclined toward commit "squashing," where multiple commits are combined into a single commit with the same net effect, or commit rebasing, where changes are included linearly rather than through a branched history.
One result of this is in figures such as Figure @fig:commit-graph, some contributors appear to have made a smaller quantity of contributions than an informed observer would recognize.
Specifically, this applies to Cl√©ment Robert, who has contributed a considerable amount of change to the code base but has done so in a way that does not maximize the "statistics" presented below.
This particular bias, toward contributions measured in count, is one that affects other members of the community as well, especially those whose participation is through community engagement, documentation, tutorials, and mentoring, rather than through direct modifications of the code base.

To mitigate this shortcoming, we present the number of pull requests merged into the code base, as a function of time, as well as the time between their creation and their merge, in Figure @fig:pr-graph.
This demonstrates that in many cases, the number of discrete contributions to the codebase varies greatly depending on the developer, and we believe gives a more informed perception of the activity in the code base.
The longest time between opening a pull request and merging it was nearly four years; this was the addition of the `cf_radial` frontend, which occurred in fits and starts over a very long period of time.
The next longest pull request durations are for splitting the code used for bitmap indexing (see @sec:point_indexing) and a per-field configuration system.
This includes only those pull requests that occurred on GitHub.

<div id="figure-commit-graph"></div>

![
Commits to the source code as a function of time.
](images/blank.svg){#fig:commit-graph width="1px"}

<script>
var commitGraphSpecification = {
  "$schema": "https://vega.github.io/schema/vega-lite/v5.json",
  "data": {"url": "images/yt_repo.json"},
  "transform": [
    {
      "timeUnit": "yearquarter",
      "field": "committed_datetime",
      "as": "commit_quarter"
    },
    {
      "aggregate": [{"op": "count", "as": "count"}],
      "groupby": ["commit_quarter", "author"]
    }
  ],
  "hconcat": [
    {
      "params": [{"name": "commit_range", "select": {"type": "interval", "encodings": ["x"]}}],
      "mark": "bar",
      "encoding": {
        "y": {
          "aggregate": "sum",
          "field": "count",
          "type": "quantitative",
          "axis": {"title": "# commits"}
        },
        "x": {
          "field": "commit_quarter",
          "type": "temporal",
          "scale": {"padding": 0}
        }
      }
    },
    {
      "transform": [
        {"filter": {"param": "commit_range"}},
        {
          "aggregate": [{"op": "sum", "field": "count", "as": "author_count"}],
          "groupby": ["author"]
        },
        {
          "window": [{"op": "rank", "as": "rank"}],
          "sort": [{"order": "descending", "field": "author_count"}]
        },
        {"filter": {"field": "rank", "lte": 10}},
        {"calculate": "split(datum['author'], ' <', 1)[0]", "as": "author_name"}
      ],
      "mark": {"type": "bar"},
      "encoding": {
        "y": {
          "field": "author_name",
          "type": "nominal",
          "axis": {"title": "top 10 authors"},
          "sort": {"order": "ascending", "field": "rank"}
        },
        "x": {
          "type": "quantitative",
          "field": "author_count",
          "scale": {"domain": [0, 9000]},
          "axis": {"title": "number of commits"}
        }
      }
    }
  ],
  "config": {
    "axis": {"labelFontSize": 16, "titleFontSize": 16},
    "legend": {"labelFontSize": 16, "titleFontSize": 16}
  }
};

vegaEmbed('#figure-commit-graph', commitGraphSpecification);

</script>

<div id="figure-pr-graph"></div>

![
Pull requests merged into the source code as a function of time.
](images/blank.svg){#fig:pr-graph width="1px"}

<script>
var prGraphSpecification = {
  "$schema": "https://vega.github.io/schema/vega-lite/v5.json",
  "data": {
    "url": "images/pr_stats.csv",
    "name": "prs",
    "format": {"parse": {"createdAt": "date", "closedAt": "date"}}
  },
  "transform": [
    {"timeUnit": "yearquarter", "field": "closedAt", "as": "closed_quarter"}
  ],
  "vconcat": [
    {
      "transform": [
        {
          "aggregate": [{"op": "count", "as": "count"}],
          "groupby": ["closed_quarter", "author"]
        }
      ],
      "hconcat": [
        {
          "params": [
            {
              "name": "closed_range",
              "select": {"type": "interval", "encodings": ["x"]}
            }
          ],
          "mark": "bar",
          "encoding": {
            "y": {
              "aggregate": "sum",
              "field": "count",
              "type": "quantitative",
              "axis": {"title": "# merged pull requests"}
            },
            "x": {
              "field": "closed_quarter",
              "type": "temporal",
              "scale": {"padding": 0},
              "axis": {"title": ""}
            }
          }
        },
        {
          "transform": [
            {"filter": {"param": "closed_range"}},
            {
              "aggregate": [
                {"op": "sum", "field": "count", "as": "author_count"}
              ],
              "groupby": ["author"]
            },
            {
              "window": [{"op": "rank", "as": "rank"}],
              "sort": [
                {"order": "descending", "field": "author_count"},
                {"order": "ascending", "field": "author"}
              ]
            },
            {"filter": {"field": "rank", "lte": 10}}
          ],
          "mark": {"type": "bar"},
          "encoding": {
            "y": {
              "field": "author",
              "type": "nominal",
              "axis": {"title": "top 10 authors"},
              "sort": {"order": "ascending", "field": "rank"}
            },
            "x": {
              "type": "quantitative",
              "field": "author_count",
              "scale": {
                "domainMax": {
                  "expr": "max(extent(pluck(data('data_2'), 'author_count'))[1], 200)"
                }
              },
              "axis": {"title": "# of closed pull requests"}
            }
          }
        }
      ]
    },
    {
      "transform": [
        {"filter": {"param": "closed_range"}},
        {"calculate": "log(datum.duration)/log(10)", "as": "log_duration"},
        {
          "bin": {"base": 10, "extent": [2, 8.2], "step": 0.25},
          "field": "log_duration",
          "as": "bin_log_duration"
        },
        {"calculate": "pow(10, datum.bin_log_duration)", "as": "x1"},
        {"calculate": "pow(10, datum.bin_log_duration_end)", "as": "x2"}
      ],
      "layer": [
        {
          "mark": "bar",
          "encoding": {
            "y": {
              "field": "x1",
              "scale": {"type": "log", "base": 10, "domain": [100, 100000000]},
              "axis": {"tickCount": 5, "title": "Seconds to Merge"},
              "type": "quantitative"
            },
            "y2": {"field": "x2"},
            "x": {"aggregate": "count", "scale": {"type": "linear", "domain": [0, 250]}}
          }
        },
        {
          "data": {
            "values": [
              {"t": 3600, "label": "1h", "y": 1},
              {"t": 86400, "label": "1d", "y": 1},
              {"t": 604800, "label": "1w", "y": 1},
              {"t": 2592000, "label": "1m", "y": 1},
              {"t": 31536000, "label": "1y", "y": 1}
            ]
          },
          "resolve": {"scale": {"x": "independent"}},
          "layer": [
            {
              "mark": "rule",
              "encoding": {
                "y": {"field": "t", "type": "quantitative"},
                "color": {"value": "black"}
              }
            },
            {
              "mark": {
                "type": "text",
                "angle": 0,
                "align": "left",
                "dy": 0,
                "dx": 5,
                "baseline": "middle"
              },
              "encoding": {
                "y": {"field": "t", "type": "quantitative"},
                "text": {"field": "label"},
                "x": {
                  "field": "y",
                  "scale": {"domain": [0, 1]},
                  "type": "quantitative",
                  "axis": {"title": "# of merged pull requests"}
                }
              }
            }
          ]
        }
      ]
    }
  ],
  "config": {
    "axis": {"labelFontSize": 16, "titleFontSize": 16},
    "legend": {"labelFontSize": 16, "titleFontSize": 16}
  }
};

vegaEmbed('#figure-pr-graph', prGraphSpecification);


</script>

### Unit Testing {#sec:unit_testing}

The `yt` codebase includes a number of unit tests; although extensive, their existence post-dates the initial development of the code, and they largely work around the extant APIs at the time of their creation.
Most modern recommendations for developing scientific software emphasize isolated components, well-structured interfaces, and few side effects.
While the development process attempts to emphasize development of isolated APIs and well-constrained unit tests, the balance struck between enabling contribution from junior developers and ensuring the (subjective) standards of the code base does not always fall on the side of rigid design.

Many of the `yt` APIs that are tested require the existence of a "dataset."
For instance, the testing of whether objects are correctly selected by a sphere selector (which absolutely *could* be tested in isolation, were the APIs more separable) is done via creating several different sets of mock datasets of different organizations and shapes and testing whether or not they correctly choose the data points to be included.
To support these operations, the `yt` testing utilities provide helper functions for creating mock datasets that have different geometric configurations and different collections of "fields" included in their set of primitive values.
Many of the tests are parameterized against the types and organizations of the datasets, the decomposition across mock processors, and the underlying values of the fields.
This ensures that we check against errors and bugs that may depend on behavior that varies as the number of processors or the organization of the data changes.
One example of this would be in the selection of grid values for a single grid of size $128^3$.
The values selected in this should match the values selected in the same grid decomposed into eight sets of $64^3$ cells, or 64 sets of $32^3$ cells.

The mechanism by which fields are tested is somewhat more extensive, touching on two different needs.
The first need is that of accuracy -- fields with known answers, or fields that can be written to be decomposed into primitive, non-optimized operations, are tested for correctness.
The second need is that of dependency calculation; all fields should have their dependencies correctly detected.
For example, if a dataset has primitive fields for "mass" and "velocity," the calculation of momentum should require both.
If the dataset includes a "momentum" field, then that should be detected as well.
This dependency calculation enables `yt` to consolidate IO tasks and read as much data as possible in each pass over the full dataset.
In addition to this, fields are tested to ensure that the values generated for them are independent of the organization of the dataset.
Like in the example above, the "momentum" field for a fixed set of values should be identical regardless of the decomposition of the individual cell elements.

Wherever possible, analytical solutions are preferred.
For processes like surface extraction, this might include ensuring that fixed radii extraction produce the correct spherical region.
For streamlines, it might include computing the analytical solution to an integration along a known vector field.
And for projections, it would mean that integrating the path with a weight of "one" should result in a uniform set of values equal to the path length across the domain.

At present, the unit tests in `yt` take a considerable amount of time to run, and are using the nosetests framework.  Modern Python practice is to use the newer pytest framework, and efforts are underway to port `yt` to utilize pytest, and in the process, attempt to reduce overall runtime.

### Answer Testing {#sec:answer_testing}

The most time-consuming part of the testing process is what we refer to as "answer testing."
Because so much of `yt` is focused on computing analysis results, and because some of these analysis results simultaneously depend on specific IO routines, selection routines, and many "frontend-specific" pieces of code, we have built a system for ensuring that for a given set of analysis operations, the result of a set of operations does not change beyond a fixed (typically quite small) tolerance.

In general, we allow three different classes of answers, against which we compare results from the current version of the code:

 1. Data values which should not ever change unless an explicit decision is made (i.e., raw data values accessed from on-disk fields)
 2. Lightly-processed data values which we do not anticipate any deviation from exact, ordered values (i.e., averages, extrema, etc.)
 3. Higher-level processed values which may differently accumulate error across platforms and architectures but are still within fine-grained ($\equiv 10^{-7}$) tolerance (i.e., images, pixelized projections, etc.)

In the first case, we can utilize hashing functions (such as MD5 and SHA) to guarantee consistency across executions.
Typically, however, we store the full set of values to facilitate easy comparison.
In the latter two cases, we apply unit-aware relative tolerances.
This allows for changes in unit assignment to be isolated from changes in value, and furthermore allows minor migration of values.
A recent incident in which these tests needed to be changed resulted from minor differences as a result of consolidating operations within a loop to conserve memory; the code in question was converted to Cython and the drift was on the scale of $10^{-10}$.

For small-scale answer tests, results are stored in a separate repository that is cloned as a subrepository of the principle ``yt`` repository.
When a new set of answers are needed, they are submitted via pull request, and the changeset hash used for answer validation is updated in the main repository.
This allows a different cadence, and also enables individuals *not* interested in updating answer values to avoid cloning the subrepository and its full history.
Larger dataset answers are stored in on our continuous integration servers; a YAML file in the main ``yt`` repository stores the current version number for those answers, which is incremented (via a pull request) when needed.
Requiring this clear decision-making process allows for both collaborative discussion and community governance over the degree of answer drift allowed.

### Code Review

Code review in `yt` is conducted on a line-by-line basis, as well as on a higher-level regarding pull requests.
The workflow for code review roughly follows this outline:

 1. A pull request is issued.  When a new pull request is issued, a template is provided that includes a description of the change, requesting information about its compliance with coding standards, etc.
 2. The pull request is automatically marked as unmergeable until a team member applies the correct component label.
 3. Code is reviewed, line-by-line, and suggestions are made by humans. Code linting, where specific behaviors are identified (such as inconsistent naming, unused variables, unreachable code sections, etc) is automated.
 4. This process is iterated, ensuring that tests, results accuracy and coding standards are maintained.

One increasing issue with the code review process is ensuring that changes are reviewed with appropriate urgency; larger pull requests tend to languish without review, as the requirements for review necessarily add burden to the maintainers.
"Bugfix" changes formally require only one reviewer, whereas the `yt` guidelines suggest that larger changes require review from two different team members.

One of the most pressing bottlenecks with code review is that the time it takes for tests to pass is much longer than the typical time span during which code review takes place.
Because tests are often required to be run on the *current* version of the code, not the version of the code against which the pull request has been issued, they are often re-initiated following a merge.
This results in a pull request being merged, and then whatever pull request is next to be reviewed has to wait until the tests (now updated with the newly accepted pull request) pass.
To alleviate this, we have recently begun utilizing the ["auto-merge" feature](https://github.blog/changelog/2021-02-04-pull-request-auto-merge-is-now-generally-available/) provided by GitHub.
This allows a maintainer to mark a pull request as "queued" to be merged once a set of requirements -- such as tests passing, approval messages, comment resolution and so forth -- are met.
By queuing up pull requests for merging, it allows maintainers to mark a set of pull requests as ready to be merged, and then when they meet the appropriate (automated and asynchronous) criteria, they will be merged.

### Code Styling and Linting

For code included in ``yt``, a set of styles are enforced.
The term "linting" is used to describe applying automated checks to enforce sytlistic consistency, as well as to flag potential errors that can be detected through static analysis of the code.

We rely on the [``pre-commit``](https://pre-commit.com) framework, which enables automated checks as well as automatic fixes at commit time.
This tool is an opt-in so not every "drive-by" contributor has to learn and install it, but continuous linting is provided by [pre-commit.ci](https://pre-commit.ci) so styling errors cannot slip in.

We configure `pre-commit` to run a mixture of formatters and static checkers.
The former modify the code in place, while the latter only report errors and so-called "code smells" (such as undefined variables, unused imports, bare `except` statements...) but require human developers fix them.

Our suite of formatter most prominently includes
[``black``](https://black.readthedocs.io/en/stable/),
[``isort``](https://pycqa.github.io/isort/) and
[``pyupgrade``](https://github.com/asottile/pyupgrade).
``black`` has been designed to maximize readability with as few free parameters as possible
(In many ways, the fact that most of the ``yt`` code developers did not utilize this style before it was enforced likely enabled its uptake, as it was seen as a choice that "made everyone compromise."),
while ``isort`` ensures that all ``import`` statements are sorted (according to alphabetical order within a first/second/third-party categorization), and ``pyupgrade`` modernizes some Python idioms according to our minimal support version of the language.
In particular, ``pyupgrade`` enforces the usage of modern Python ["f-strings"](https://docs.python.org/3/tutorial/inputoutput.html#formatted-string-literals) since we do not support Python version older than 3.6.

For static code analysis we rely on the [``flake8``](https://flake8.pycqa.org/en/latest/) framework.
Effort is underway to enable using `mypy` for the specialized task of type checking.

All changes that can be applied via automation (specifically, code formatting) are accessible from within the GitHub pull request interface, and are again provided by [pre-commit.ci](https://pre-commit.ci).
This allows drive-by contributions to have their pull requests updated inline by an automated process, reducing the need to manually install packages to apply the changes.

We note that in @doi:10.1109/icsme46990.2020.00011 evidence is presented that code review bots can lead to a reduction in rejected pull requests, as well as decreased communication among developers.
While yt is not necessarily the perfect laboratory for this, as the project as a whole does not have an extensive history of declining pull requests, we have anecdotally noted that discussion around 'code nits' and stylistic issues has been considerably reduced, leading to what developers describe as expedited pull requests.

### Type Hinting

Code included in ``yt`` is not required to utilize [type hinting](https://docs.python.org/3/library/typing.html).
However, new contributions are allowed to include type hinting, and work is underway to develop an ontology of types as well as a base set of utilities and types that would be used both internally, and possibly be made available to external package developers.

### YTEP Process {#sec:ytep}

YTEPs, or "`yt`-enhancement proposal" are vehicles for collaborative decision-making in the project.
During periods of rapid development, the needs of the community for stability have to be balanced against desires for change; the YTEP process was implemented to facilitate stakeholder feedback, allow for discussion of design decisions, and to prompt detailed thinking about how and why things should be implemented.
We have modeled this process against that used in the AstroPy community ("APE").
To create a new proposal for a large change to `yt`, or to document a decision-making process, individuals prepare a description of the background, motivation for the change, the steps to implementation, and potential alternative approaches.
The proposal is discussed through the pull-request process, and once discussion has concluded it is added to the [repository](https://github.com/yt-project/ytep) of YTEPs that is auto-built and [deployed](https://ytep.readthedocs.org/).

Implemented shortly after the first paper on `yt` was released, the YTEP process experienced a fairly pronounced period of usage during the transition between versions 2.0 and 3.0 of `yt`, and has since been utilized considerably less.
The accepted YTEPs have included implementing the chunking system, developing a units system, removing legacy components, and implementing a code of conduct.
Below, we include a table of current YTEPs as of this writing.

| Number   | YTEP Title                                            | Created            | Authors                                                             |
|----------|-------------------------------------------------------|--------------------|---------------------------------------------------------------------|
| 0001     | IO Chunking                                           | November 26, 2012  | Matthew Turk                                                        |
| 0002     | Profile Plotter                                       | December 5, 2012   | Matthew Turk                                                        |
| 0003     | Standardizing field names                             | December 11, 2012  | Casey Stark, Nathan Goldbaum, Matthew Turk                          |
| 0005     | Octrees for Fluids and Particles                      | December 24, 2012  | Matthew Turk                                                        |
| 0006     | Periodicity                                           | January 10, 2013   | Matthew Turk, Nathan Goldbaum                                       |
| 0007     | Automatic Pull Requests' validation                   | February 21, 2013  | Kacper Kowalik                                                      |
| 0008     | Release Schedule                                      | February 21, 2013  | Matthew Turk                                                        |
| 0009     | AMRKDTree for Data Sources                            | February 28, 2012  | Sam Skillman                                                        |
| 0010     | Refactoring for Volume Rendering and Movie Generation | March 3, 2013      | Cameron Hummels                                                     |
| 0011     | Symbol units in yt                                    | March 7, 2013      | Nathan Goldbaum, Casey Stark, Anna Rosen, Matthew Turk              |
| 0012     | Halo Redesign                                         | March 7, 2013      | Britton Smith, Cameron Hummels, Chris Moody, Mark Richardson, Yu Lu |
| 0013     | Deposited Particle Fields                             | April 25, 2013     | Chris Moody, Matthew Turk, Britton Smith, Doug Rudd, Sam Leitner    |
| 0014     | Field Filters                                         | July 2nd, 2013     | Matthew Turk                                                        |
| 0015     | Transfer Function Refactor                            | August 13, 2013    | Sam Skillman                                                        |
| 0016     | Volume Traversal                                      | September 10, 2013 | Matthew Turk                                                        |
| 0017     | Domain-Specific Output Types                          | September 18, 2013 | Matthew Turk and Anthony Scopatz                                    |
| 0018     | Changing dict-like access to Static Output            | September 18, 2013 | Matthew Turk                                                        |
| 0019     | Reduce items in main import                           | October 2, 2013    | Matthew Turk                                                        |
| 0020     | Removing PlotCollection                               | March 18, 2014     | Matthew Turk                                                        |
| 0021     | Particle-Only Plots                                   | August 29, 2014    | Andrew Myers                                                        |
| 0022     | Benchmarks                                            | January 19, 2015   | Matthew Turk                                                        |
| 0023     | yt Community Code of Conduct                          | July 11, 2015      | Britton Smith                                                       |
| 0024     | Alternative Smoothing Kernels                         | August 1, 2015     | Bili Dong                                                           |
| 0025     | The ytdata Frontend                                   | August 31, 2015    | Britton Smith                                                       |
| 0026     | NumPy-like Operations                                 | September 21, 2015 | Matthew Turk                                                        |
| 0027     | Non-Spatial Data                                      | December 1, 2015   | Matthew Turk, Nathan Goldbaum, John ZuHone                          |
| 0028     | Alternative Unit Systems                              | December 8, 2015   | John ZuHone, Nathan Goldbaum, Matthew Turk                          |
| 0029     | Extension Packages                                    | January 25, 2016   | Matthew Turk                                                        |
| 0031     | Unstructured Mesh                                     | December 18, 2014  | Matthew Turk                                                        |
| 0032     | Removing the global octree mesh for particle data     | February 9 2017    | Nathan Goldbaum, Meagan Lang, Matthew Turk                          |
| 0033     | Dropping Python2 Support                              | November 28, 2017  | Nathan Goldbaum                                                     |
| 0034     | yt FITS Image Standard                                | September 9, 2018  | John ZuHone                                                         |
| 0036     | Migrating from nose to pytest                         | September 30, 2019 | Jared Coughlin                                                      |
| 0037     | Code Styling                                          | May 18, 2020       | Cl√©ment Robert                                                      |
| 1000     | GitHub Migration                                      | March 25, 2017     | Lots of folks                                                       |
| 1776     | Team Infrastructure                                   | August 24, 2014    | Britton Smith                                                       |
| 3000     | Let's all start using yt 3.0!                         | October 30, 2013   | Matthew Turk                                                        |
